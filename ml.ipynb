{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-13T23:48:12.252222637Z",
     "start_time": "2023-11-13T23:48:11.095591501Z"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ML model for movie recommendation based on user input of film. Uses NearestNeighbor to determine the closest movie based on genres of the given movie input"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e35ca0b4fb9fecfc"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(   1,                           'Toy Story (1995)', ...),\n",
      "            ( 924,               '2001: A Space Odyssey (1968)', ...),\n",
      "            (1073, 'Willy Wonka & the Chocolate Factory (1971)', ...),\n",
      "            (1240,                     'Terminator, The (1984)', ...),\n",
      "            (1028,                        'Mary Poppins (1964)', ...)],\n",
      "           names=['movieId', 'title', 'genres'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Carregando os DataFrames a partir dos arquivos CSV\n",
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Merge dos dataframes\n",
    "merged_data = ratings.merge(movies, on='movieId')\n",
    "result = merged_data[['userId', 'movieId', 'title', 'genres', 'rating']]\n",
    "\n",
    "# Filtrar usuários e filmes com base no número de avaliações\n",
    "contagem_avaliacoes = result.groupby('userId').size().reset_index(name='qtd_avaliacoes')\n",
    "contagem_avaliacoes = contagem_avaliacoes.loc[contagem_avaliacoes['qtd_avaliacoes'] > 30]\n",
    "result = result[result['userId'].isin(contagem_avaliacoes['userId'])]\n",
    "\n",
    "#Filtrar filmes que possuem mais de 50 avaliações\n",
    "filmes_avaliacoes = result.groupby('movieId').size().reset_index(name='qtd_avaliacoes')\n",
    "filmes_avaliacoes = filmes_avaliacoes.loc[filmes_avaliacoes['qtd_avaliacoes'] > 50]\n",
    "filmes_avaliacoes = filmes_avaliacoes.merge(result[['movieId', 'title', 'genres']], on='movieId', how='left').drop_duplicates()\n",
    "result = result[result['movieId'].isin(filmes_avaliacoes['movieId'])]\n",
    "\n",
    "#Transformar em binário os genêros\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_one_hot = mlb.fit_transform(result['genres'].str.split('|'))\n",
    "genres_one_hot_df = pd.DataFrame(genres_one_hot, columns=mlb.classes_, index=result.index)\n",
    "\n",
    "# Concatenar as variáveis binárias com o dataframe result\n",
    "result_with_genres = pd.concat([result, genres_one_hot_df], axis=1)\n",
    "\n",
    "# Pivot table com os gêneros para cada usuário e filme\n",
    "result_pivot = result_with_genres.pivot_table(index=['movieId','title', 'genres'], values='rating', fill_value=0)\n",
    "result_pivot.fillna(0.0, inplace=True)\n",
    "# Criar a matriz esparsa\n",
    "filmes_sparse = csr_matrix(result_pivot)\n",
    "# Criando e treinando o modelo preditivo\n",
    "modelo = NearestNeighbors(algorithm = 'brute')\n",
    "modelo.fit(filmes_sparse)\n",
    "#print(result_pivot.iloc[0]) #ToyStory\n",
    "distances, suggestions = modelo.kneighbors(result_pivot.iloc[0].values.reshape(1, -1))\n",
    "for i in range(len(suggestions)):\n",
    "    print(result_pivot.index[suggestions[i]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T05:07:22.842358921Z",
     "start_time": "2023-11-30T05:07:22.687358334Z"
    }
   },
   "id": "38e8ef2485185916"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ML model for prediction of movie rating KNeighborsRegressor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4da4d7f19b5f6de0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "899f9676adb320bd"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       rating\n",
      "0    3.483607\n",
      "1    3.518797\n",
      "2    3.466019\n",
      "3    3.703125\n",
      "4    3.888889\n",
      "..        ...\n",
      "334  3.540000\n",
      "335  3.306034\n",
      "336  3.475806\n",
      "337  3.711538\n",
      "338  3.539474\n",
      "\n",
      "[339 rows x 1 columns]\n",
      "Root Mean Squared Error (RMSE): 0.38576959914593606\n",
      "Mean Absolute Error (MAE): 0.3181010739912461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ian/projetos/MACHINE_LEARNING/venv/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Carregando os DataFrames a partir dos arquivos CSV\n",
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "\n",
    "# Merge dos dataframes\n",
    "merged_data = ratings.merge(movies, on='movieId')\n",
    "result = merged_data[['userId', 'movieId', 'title', 'genres', 'rating']]\n",
    "\n",
    "# Filtrar usuários e filmes com base no número de avaliações\n",
    "contagem_avaliacoes = result.groupby('userId').size().reset_index(name='qtd_avaliacoes')\n",
    "contagem_avaliacoes = contagem_avaliacoes.loc[contagem_avaliacoes['qtd_avaliacoes'] > 30]\n",
    "result = result[result['userId'].isin(contagem_avaliacoes['userId'])]\n",
    "\n",
    "#Filtrar filmes que possuem mais de 50 avaliações\n",
    "filmes_avaliacoes = result.groupby('movieId').size().reset_index(name='qtd_avaliacoes')\n",
    "filmes_avaliacoes = filmes_avaliacoes.loc[filmes_avaliacoes['qtd_avaliacoes'] > 50]\n",
    "filmes_avaliacoes = filmes_avaliacoes.merge(result[['movieId', 'title', 'genres']], on='movieId', how='left').drop_duplicates()\n",
    "result = result[result['movieId'].isin(filmes_avaliacoes['movieId'])]\n",
    "\n",
    "#Transformar em binário os genêros\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_one_hot = mlb.fit_transform(result['genres'].str.split('|'))\n",
    "genres_one_hot_df = pd.DataFrame(genres_one_hot, columns=mlb.classes_, index=result.index)\n",
    "\n",
    "# Concatenar as variáveis binárias com o dataframe result\n",
    "result_with_genres = pd.concat([result, genres_one_hot_df], axis=1)\n",
    "\n",
    "# Pivot table com os gêneros para cada usuário e filme\n",
    "result_pivot = result_with_genres.pivot_table(index=['movieId', 'genres'], values='rating', fill_value=0)\n",
    "result_pivot.fillna(0.0, inplace=True)\n",
    "# Criar a matriz esparsa\n",
    "filmes_sparse = csr_matrix(result_pivot)\n",
    "# Divisão entre dados de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_pivot.index, result_pivot.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting the MultiIndex to a DataFrame\n",
    "X_train_df = X_train.to_frame(index=False)\n",
    "X_test_df = X_test.to_frame(index=False)\n",
    "# Fit the encoder on training data and transform both train and test data\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "X_train_encoded = encoder.fit_transform(X_train_df)\n",
    "X_test_encoded = encoder.transform(X_test_df)\n",
    "\n",
    "# Assuming y_train is a single-column array containing ratings\n",
    "# Converting it to a DataFrame\n",
    "y_train_df = pd.DataFrame(y_train, columns=['rating'])\n",
    "\n",
    "# Training the model\n",
    "modelo = KNeighborsRegressor()\n",
    "modelo.fit(X_train_encoded, y_train_df)\n",
    "print(y_train_df)\n",
    "# Make predictions on the test set\n",
    "predictions = modelo.predict(X_test_encoded)\n",
    "\n",
    "# Calculate RMSE and MAE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T23:04:10.400811423Z"
    }
   },
   "id": "751e655c6791e9d0"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e4ed6d11b36f941"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T01:49:51.709145225Z"
    }
   },
   "id": "c94897554a6b16e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8f35a59073a7aa8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformação do DF em pivot para aplicar algoritimo KNN"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15b72ce85c4f8134"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required by NearestNeighbors.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[85], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m result_pivot\u001B[38;5;241m.\u001B[39mhead()\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Obter recomendações com base nos gêneros do filme '300 (2007)'\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m distances, sugestions \u001B[38;5;241m=\u001B[39m \u001B[43mmodelo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkneighbors\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult_pivot\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitems\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mAlien (1979)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalues\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(distances)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m#for i, movie_index in enumerate(sugestions):\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m#    movie_title = result_pivot.iloc[movie_index]\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m#    print(f\"{i + 1}. {movie_title}\")\u001B[39;00m\n",
      "File \u001B[0;32m~/projetos/MACHINE_LEARNING/venv/lib/python3.10/site-packages/sklearn/neighbors/_base.py:804\u001B[0m, in \u001B[0;36mKNeighborsMixin.kneighbors\u001B[0;34m(self, X, n_neighbors, return_distance)\u001B[0m\n\u001B[1;32m    802\u001B[0m         X \u001B[38;5;241m=\u001B[39m _check_precomputed(X)\n\u001B[1;32m    803\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 804\u001B[0m         X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    806\u001B[0m n_samples_fit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_samples_fit_\n\u001B[1;32m    807\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_neighbors \u001B[38;5;241m>\u001B[39m n_samples_fit:\n",
      "File \u001B[0;32m~/projetos/MACHINE_LEARNING/venv/lib/python3.10/site-packages/sklearn/base.py:605\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    603\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    604\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 605\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[1;32m    607\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[0;32m~/projetos/MACHINE_LEARNING/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:976\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    974\u001B[0m     n_features \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    975\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m<\u001B[39m ensure_min_features:\n\u001B[0;32m--> 976\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    977\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m feature(s) (shape=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) while\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    978\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m a minimum of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m is required\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    979\u001B[0m             \u001B[38;5;241m%\u001B[39m (n_features, array\u001B[38;5;241m.\u001B[39mshape, ensure_min_features, context)\n\u001B[1;32m    980\u001B[0m         )\n\u001B[1;32m    982\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy:\n\u001B[1;32m    983\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_numpy_namespace(xp):\n\u001B[1;32m    984\u001B[0m         \u001B[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required by NearestNeighbors."
     ]
    }
   ],
   "source": [
    "\n",
    "# Criar a matriz esparsa\n",
    "filmes_sparse = csr_matrix(result_pivot)\n",
    "\n",
    "# Treinar o modelo k-NN\n",
    "modelo = NearestNeighbors(algorithm='brute')\n",
    "modelo.fit(filmes_sparse)\n",
    "result_pivot.head()\n",
    "# Obter recomendações com base nos gêneros do filme '300 (2007)'\n",
    "distances, sugestions = modelo.kneighbors(result_pivot.filter(items=['Alien (1979)'], axis=0).values.reshape(1,-1))\n",
    "print(distances)\n",
    "#for i, movie_index in enumerate(sugestions):\n",
    "#    movie_title = result_pivot.iloc[movie_index]\n",
    "#    print(f\"{i + 1}. {movie_title}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-30T05:09:38.080078144Z",
     "start_time": "2023-11-30T05:09:38.031031440Z"
    }
   },
   "id": "a9a9170819ad370e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-30T01:49:51.709677028Z"
    }
   },
   "id": "99acada877c41d22"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
